# analog-meter-reading
Пайплайн для задач регрессии на основе машинного обучения
Этот репозиторий содержит модульный пайплайн на Python, предназначенный для решения задач регрессии. Пайплайн включает загрузку данных, их предобработку, обучение нескольких моделей, оценку их производительности и выбор лучшей модели на основе ключевых метрик.
Обзор
Пайплайн организован в виде последовательности функций, которые работают вместе для упрощения процесса обучения и оценки моделей машинного обучения. Он поддерживает загрузку данных из нескольких CSV-файлов, разделение данных на обучающую и тестовую выборки, сравнение различных алгоритмов и выбор лучшей модели на основе метрик, таких как R², RMSE и улучшение по сравнению с базовым уровнем.
Основные возможности
    Загрузка и предобработка данных:
        Загрузка данных из нескольких CSV-файлов.
        Объединение наборов данных в один DataFrame для анализа.
        Разделение данных на признаки (X) и целевые значения (y).

    Обучение и оценка моделей:
        Сравнение нескольких алгоритмов регрессии (Random Forest, XGBoost, Линейная регрессия).
        Оценка моделей с использованием метрик, таких как R², RMSE и процент улучшения над базовым уровнем.
        Измерение времени обучения и предсказания для каждой модели.

    Выбор лучшей модели:
        Автоматический выбор лучшей модели на основе максимального значения R².
        Повторное обучение лучшей модели на полном обучающем наборе данных.

    Масштабируемость:
        Поддержка загрузки подмножества строк (nrows) для быстрого экспериментирования с большими наборами данных.

Структура пайплайна
1. Загрузка данных
Функция load_data загружает данные из указанных CSV-файлов и объединяет их в один DataFrame. Также она разделяет признаки и целевые значения.
def load_data(base_path, data_files, target_files, nrows=10000):
    """
    Загружает и объединяет данные из нескольких CSV-файлов.
    :param base_path: Путь к папке с файлами.
    :param data_files: Список файлов с признаками.
    :param target_files: Список файлов с целевыми значениями.
    :param nrows: Количество строк для загрузки из каждого файла.
    :return: Объединенные признаки и целевые значения.
    """

2. Разделение данных
Функция split_data разделяет данные на обучающую и тестовую выборки.
def split_data(data, target, test_size=0.2, random_state=42):
    """
    Разделяет данные на обучающую и тестовую выборки.
    :param data: Признаки (DataFrame).
    :param target: Целевые значения (DataFrame или Series).
    :param test_size: Доля данных для тестовой выборки.
    :param random_state: Случайное состояние для воспроизводимости.
    :return: X_train, X_test, y_train, y_test
    """
3. Оценка модели
Функция evaluate_model обучает заданную модель и оценивает её производительность с использованием метрик, таких как R², RMSE и улучшение над базовым уровнем.
def evaluate_model(model, X_train, X_test, y_train, y_test):
    """
    Обучает и оценивает модель машинного обучения.
    :param model: Модель машинного обучения.
    :param X_train, X_test, y_train, y_test: Обучающие и тестовые данные.
    :return: Словарь с метриками и временем выполнения.
    """

4. Сравнение моделей
Функция compare_models сравнивает несколько алгоритмов регрессии и возвращает их метрики производительности.
def compare_models(X_train, X_test, y_train, y_test):
    """
    Сравнивает несколько алгоритмов регрессии.
    :param X_train, X_test, y_train, y_test: Обучающие и тестовые данные.
    :return: Список результатов для каждой модели.
    """
5. Полный пайплайн
Функция pipeline управляет всем процессом, от загрузки данных до выбора и оценки лучшей модели.
def pipeline(base_path, data_files, target_files, nrows=10000):
    """
    Пайплайн для обучения и оценки моделей регрессии.
    :param base_path: Путь к папке с файлами.
    :param data_files: Список файлов с признаками.
    :param target_files: Список файлов с целевыми значениями.
    :param nrows: Количество строк для загрузки из каждого файла.
    :return: Лучшая обученная модель и её метрики.
    """
Пример использования
Для запуска пайплайна укажите пути к вашим файлам данных и выполните скрипт:

if __name__ == "__main__":
    # Пути к файлам данных
    base_path = "/home/c3/Загрузки/BIG DATA"
    data_files = ["df_0.csv", "df_1.csv", "df_2.csv", "df_3.csv"]
    target_files = ["target_0.csv", "target_1.csv", "target_2.csv", "target_3.csv"]

    # Запуск пайплайна
    model, metrics = pipeline(base_path, data_files, target_files, nrows=10000)
    print("\nЛучшая модель:", model)
    print("Метрики на тестовой выборке:", metrics)

Зависимости:
    pandas
    numpy
    scikit-learn
    xgboost
    time

Установите зависимости с помощью pip:
pip install pandas numpy scikit-learn xgboost

Вывод
Пайплайн выводит:
    Сравнение всех оцененных моделей с метриками, такими как R², RMSE, процент улучшения, время обучения и время предсказания.
    Лучшую модель на основе максимального значения R².
    Подробные метрики для лучшей модели на тестовой выборке.

Планы на будущее
    Добавить поддержку дополнительных алгоритмов регрессии (например, Gradient Boosting, SVR).
    Реализовать подбор гиперпараметров с использованием GridSearchCV или Bayesian Optimization.
    Добавить логирование для лучшего отслеживания экспериментов.
    Добавить поддержку других форматов файлов (например, JSON, Parquet).

